<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Baabedo Trader</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="./papaparse.js"></script>
  <script src="http://cs.stanford.edu/people/karpathy/convnetjs/build/convnet-min.js"></script>
  <script src="./build/util.js"></script>
  <script src="./build/vis.js"></script>
  <script src="./build/deepqlearn.js"></script>
  <script src="./build/env.js"></script>
  <script type="application/javascript">
    window.onload = function() {
      var num_inputs = 452; // 9 eyes, each sees 3 numbers (wall, green, red thing proximity)
      // actions: do nothing(hold); buy (5000); sell(all)
      var num_actions = 3; // 5 possible angles agent can turn
      var temporal_window = 1; // amount of temporal memory. 0 = agent lives in-the-moment :)
      var network_size = num_inputs*temporal_window + num_actions*temporal_window + num_inputs;

      // the value function network computes a value of taking any of the possible actions
      // given an input state. Here we specify one explicitly the hard way
      // but user could also equivalently instead use opt.hidden_layer_sizes = [20,20]
      // to just insert simple relu hidden layers.
      var layer_defs = [];
      layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:network_size});
      layer_defs.push({type:'fc', num_neurons: 50, activation:'relu'});
      layer_defs.push({type:'fc', num_neurons: 50, activation:'relu'});
      layer_defs.push({type:'regression', num_neurons:num_actions});

      // options for the Temporal Difference learner that trains the above net
      // by backpropping the temporal difference learning rule.
      var tdtrainer_options = {learning_rate:0.001, momentum:0.0, batch_size:90, l2_decay:0.01};

      var opt = {};
      opt.temporal_window = temporal_window;
      opt.experience_size = 30000;
      opt.start_learn_threshold = 1000;
      opt.gamma = 0.7;
      opt.learning_steps_total = 200000;
      opt.learning_steps_burnin = 3000;
      opt.epsilon_min = 0.05;
      opt.epsilon_test_time = 0.05;
      opt.layer_defs = layer_defs;
      opt.tdtrainer_options = tdtrainer_options;

      var brain = new deepqlearn.Brain(num_inputs, num_actions, opt);
      brain.visSelf(document.getElementById('brain_info'));

      var env = new deepqlearn.Market(document.getElementById('env_info'));

      document.getElementById('start').addEventListener("click", function(){
        setInterval(function() {
          if(env.current <= 0) {
            env = new deepqlearn.Market(document.getElementById('env_info'));
          }
          current_states = env.get_new_state();
          //for (var key in current_states) {
            var key = 0;
            var state = current_states[key];
            var action = brain.forward(state);
            var reward = env.do_action(parseInt(key), action);
            console.log(action, reward);
            brain.backward(reward);
            env.visSelf();
            brain.visSelf(document.getElementById('brain_info'))
          //}
        }, 50);
      });
    }
  </script>
</head>
<body>
  <button style="display:none" id="start">LET IT LEARN</button>
  <div id="env_info"></div>
  <br/>
  <div id="brain_info"></div>
</body>
</html>
